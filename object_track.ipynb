{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pylab\n",
    "import os\n",
    "import shutil\n",
    "import imageio\n",
    "from collections import deque\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "import imutils\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(\"images\")\n",
    "except:\n",
    "    shutil.rmtree(\"images\")\n",
    "    os.mkdir(\"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "greenLower = (29, 86, 6)\n",
    "greenUpper = (64, 255, 255)\n",
    " \n",
    "# initialize the list of tracked points, the frame counter,\n",
    "# and the coordinate deltas\n",
    "pts = deque(maxlen=20)\n",
    "counter = 0\n",
    "(dX, dY) = (0, 0)\n",
    "direction = \"\"\n",
    "filename = 'test_sample1.avi'\n",
    "vid = imageio.get_reader(filename,  'ffmpeg')\n",
    "count = 0\n",
    "for num in range(vid.get_length()):\n",
    "    try:\n",
    "        img = vid.get_data(num)\n",
    "        \n",
    "        img = cv2.resize(img,(1000,600))\n",
    "        gray_image = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        _,im =  cv2.threshold(gray_image,220,1,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        \n",
    "        image, cnts, hier = cv2.findContours(im,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "        center = None\n",
    "        for c in cnts:\n",
    "            x, y, w, h = cv2.boundingRect(c)\n",
    "\n",
    "            # draw a green rectangle to visualize the bounding rect\n",
    "            cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "            # get the min area rect\n",
    "            rect = cv2.minAreaRect(c)\n",
    "            box = cv2.boxPoints(rect)\n",
    "\n",
    "            # convert all coordinates floating point values to int\n",
    "            box = np.int0(box)\n",
    "\n",
    "            # draw a red 'nghien' rectangle\n",
    "            cv2.drawContours(img, [box], 0, (0, 0, 255))\n",
    "        # only proceed if at least one contour was found\n",
    "        \n",
    "        if len(cnts) > 1:\n",
    "            \n",
    "            # Change objects for finding trajectory\n",
    "            # By changing the value of -2 to any other integer you can change the tracking\n",
    "            # if you change it to -3 it will pickup the object which has third largest area  \n",
    "            # and so on. but the area of objects will change as you move and rotate the image\n",
    "            # So it will not give much accurate results\n",
    "            # -2 works best because it is the second largest area. first largest area is usually \n",
    "            # the full video size.\n",
    "            c = sorted(cnts, key=cv2.contourArea)[-2]\n",
    "            \n",
    "            # for tracking most dominant object uncomment this and comment above  line\n",
    "#             c = [contour for contour in sorted(cnts, key=cv2.contourArea)[::-1] if cv2.contourArea(contour)< 450000][0]\n",
    "             \n",
    "            \n",
    "            ((x, y), radius) = cv2.minEnclosingCircle(c)\n",
    "            M = cv2.moments(c)\n",
    "            center = (int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"]))\n",
    "            cv2.circle(img, (int(x), int(y)), int(radius),\n",
    "                (0, 255, 255), 2)\n",
    "            cv2.circle(img, center, 5, (0, 0, 255), -1)\n",
    "            pts.appendleft(center)\n",
    "            \n",
    "        # loop over the set of tracked points\n",
    "        for i in np.arange(1, len(pts)):\n",
    "            # if either of the tracked points are None, ignore\n",
    "            # them\n",
    "            if pts[i - 1] is None or pts[i] is None:\n",
    "                continue\n",
    "                # check to see if enough points have been accumulated in\n",
    "                # the buffer\n",
    "            if counter >= 10 and i == 1 and pts[-10] is not None:\n",
    "                # compute the difference between the x and y\n",
    "                # coordinates and re-initialize the direction\n",
    "                # text variables\n",
    "                dX = pts[-10][0] - pts[i][0]\n",
    "                dY = pts[-10][1] - pts[i][1]\n",
    "                (dirX, dirY) = (\"\", \"\")\n",
    "\n",
    "                # ensure there is significant movement in the\n",
    "                # x-direction\n",
    "                if np.abs(dX) > 20:\n",
    "                    dirX = \"East\" if np.sign(dX) == 1 else \"West\"\n",
    "\n",
    "                # ensure there is significant movement in the\n",
    "                # y-direction\n",
    "                if np.abs(dY) > 20:\n",
    "                    dirY = \"North\" if np.sign(dY) == 1 else \"South\"\n",
    "\n",
    "                # handle when both directions are non-empty\n",
    "                if dirX != \"\" and dirY != \"\":\n",
    "                    direction = \"{}-{}\".format(dirY, dirX)\n",
    "\n",
    "                # otherwise, only one direction is non-empty\n",
    "                else:\n",
    "                    direction = dirX if dirX != \"\" else dirY\n",
    "            # otherwise, compute the thickness of the line and\n",
    "            # draw the connecting lines\n",
    "            thickness = int(np.sqrt(15 / float(i + 1)) * 2.5)\n",
    "            cv2.line(img, pts[i - 1], pts[i], (0, 0, 255), thickness)\n",
    "\n",
    "        # show the movement deltas and the direction of movement on\n",
    "        # the frame\n",
    "    #         cv2.drawContours(img, cnts[1], -1, (255, 255, 0), 1)\n",
    "        cv2.putText(img, direction, (10, 30), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.65, (0, 0, 255), 3)\n",
    "        cv2.putText(img, \"dx: {}, dy: {}\".format(dX, dY),\n",
    "            (10, img.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.35, (0, 0, 255), 1)\n",
    "\n",
    "        # show the frame to our screen and increment the frame counter\n",
    "        cv2.imshow(\"Frame\", img)\n",
    "        count += 1\n",
    "        cv2.imwrite(\"images/\"+\"image-\"+str(count)+\".jpg\",img)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        counter += 1\n",
    "\n",
    "        # if the 'q' key is pressed, stop the loop\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "# cleanup the camera and close any open windows\n",
    "# camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %rm -rf output-vid.avi\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 2.7 Copyright (c) 2000-2015 the FFmpeg developers\n",
      "  built with llvm-gcc 4.2.1 (LLVM build 2336.11.00)\n",
      "  configuration: --prefix=/Volumes/Ramdisk/sw --enable-gpl --enable-pthreads --enable-version3 --enable-libspeex --enable-libvpx --disable-decoder=libvpx --enable-libmp3lame --enable-libtheora --enable-libvorbis --enable-libx264 --enable-avfilter --enable-libopencore_amrwb --enable-libopencore_amrnb --enable-filters --enable-libgsm --enable-libvidstab --enable-libx265 --disable-doc --arch=x86_64 --enable-runtime-cpudetect\n",
      "  libavutil      54. 27.100 / 54. 27.100\n",
      "  libavcodec     56. 41.100 / 56. 41.100\n",
      "  libavformat    56. 36.100 / 56. 36.100\n",
      "  libavdevice    56.  4.100 / 56.  4.100\n",
      "  libavfilter     5. 16.101 /  5. 16.101\n",
      "  libswscale      3.  1.101 /  3.  1.101\n",
      "  libswresample   1.  2.100 /  1.  2.100\n",
      "  libpostproc    53.  3.100 / 53.  3.100\n",
      "Input #0, image2, from 'images/image-%00d.jpg':\n",
      "  Duration: 00:00:23.56, start: 0.000000, bitrate: N/A\n",
      "    Stream #0:0: Video: mjpeg, yuvj420p(pc, bt470bg/unknown/unknown), 1000x600 [SAR 1:1 DAR 5:3], 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
      "\u001b[1;34m[swscaler @ 0x7ff6950a8c00] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0mOutput #0, avi, to 'output-vid.avi':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf56.36.100\n",
      "    Stream #0:0: Video: mpeg4 (FMP4 / 0x34504D46), yuv420p, 1280x720 [SAR 15:16 DAR 5:3], q=2-31, 200 kb/s, 76 fps, 76 tbn, 76 tbc\n",
      "    Metadata:\n",
      "      encoder         : Lavc56.41.100 mpeg4\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mjpeg (native) -> mpeg4 (native))\n",
      "Press [q] to stop, [?] for help\n",
      "frame=  589 fps=115 q=24.8 Lsize=    2276kB time=00:00:23.53 bitrate= 792.1kbits/s    \n",
      "video:2228kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 2.147721%\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -i images/image-%00d.jpg -r 76 -s 1280x720 output-vid.avi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = sorted(cnts, key=cv2.contourArea)[::-1][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595087.5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.contourArea(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.resize(img,(1000,600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 1000, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
